---
title: "PROJECT 4:Document Classification - 607"
author: "Blessing Anoroh"
date: "April 25, 2024"
output: html_document
---

## Task

It can be useful to be able to classify new "test" documents using already classified "training" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  

For this project, you can start with a spam/ham dataset, then predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).   One example corpus:   https://spamassassin.apache.org/old/publiccorpus/


## Load Packages

```{r , message = FALSE}
library(tm)
library(tmap)
library(readr)
library(tidyr)
library(dplyr)
library( stringr)
library(tidytext)
library(caret)

```


## Load Data and Tidy

First, we will load the files from the spam and ham folders into R.
Then we transform the text from each email into the data frame.
There are 2551 ham and 1398 spam messages.

```{r}
#Retrieving the respective ham and spam filenames
spam_dir <- "/Users/blessinga/Desktop/Masters Data Science/607 /Project 4/spam_2"
ham_dir <-  "/Users/blessinga/Desktop/Masters Data Science/607 /Project 4/easy_ham"
```


```{r}
sh_df <- function(path, tag){
  files <- list.files(path=path, full.names=TRUE, recursive=TRUE)
  email <- lapply(files, function(x) {
    body <- read_file(x)
    })
  email <- unlist(email)
  data <- as.data.frame(email)
  data$tag <- tag
  return (data)
}

ham_df_file <- sh_df(ham_dir, tag="ham") 
spam_df_file <- sh_df(spam_dir, tag="spam")
ham_spam_df <- rbind(ham_df_file, spam_df_file)
table(ham_spam_df$tag)
```


## Process and Prepare Data

Next, we get rid of unnecessary data.

```{r}

ham_spam_df<-ham_spam_df %>%
  mutate(email = str_remove_all(email, pattern = "<.*?>")) %>%
  mutate(email = str_remove_all(email, pattern = "[:digit:]")) %>%
  mutate(email = str_remove_all(email, pattern = "[:punct:]")) %>%
  mutate(email = str_remove_all(email, pattern = "[\n]")) %>%
  mutate(email = str_to_lower(email)) %>%
 unnest_tokens(output=text,input=email,
                token="paragraphs",
                format="text") %>%
 anti_join(stop_words, by=c("text"="word"))
```


## Corpus , Document Term Matrix

Then we need to shuffle the spam and ham emails in the data frame.

```{r}
set.seed(7614)
shuffled <- sample(nrow(ham_spam_df))
ham_spam_df<-ham_spam_df[shuffled,]
ham_spam_df$tag <- as.factor(ham_spam_df$tag)
```


Then we Clean the corpus by removing punctuation, numbers, and stop words using function tm_map.

```{r}
n_corp <- VCorpus(VectorSource(ham_spam_df$text))
n_corp <- tm_map(n_corp, removeNumbers)
n_corp <- tm_map(n_corp, removePunctuation)
n_corp <- tm_map(n_corp, stripWhitespace)
n_corp <- tm_map(n_corp, removeWords, stopwords("english")) 
n_corp <- tm_map(n_corp, stemDocument)
n_corp <- tm_map(n_corp, content_transformer(stringi::stri_trans_tolower))
```


Then using the following functions:  \
DocumentTermMatrix() we will contract document Term Matrix from our data frame, \
and with removeSparseTerms() we will remove sparse terms .

```{r}
ham_spam_tm <- DocumentTermMatrix(n_corp, control = list(stemming = TRUE))
ham_spam_tm <- removeSparseTerms(ham_spam_tm, 0.999)

co_count <- function(x) {
  y <- ifelse(x > 0, 1,0)
  y <- factor(y, levels=c(0,1), labels=c(0,1))
  y
}

tmp_df <- apply(ham_spam_tm, 2, co_count)

spam_ham_matrix = as.data.frame(as.matrix(tmp_df))

spam_ham_matrix$class = spam_ham_matrix$class
str(spam_ham_matrix$class)

```


## Prediction (and Results)

Using library caret.
The training data frame will take 0.7 = 70% of the data, and 0.3 = 30% data we will leave for testing. \
Function createDataPartition() is used to create series of test/training partitions.

```{r}
set.seed(7312)  
pred <- createDataPartition(spam_ham_matrix$class, p=.7, list = FALSE, times = 1)
head(pred)
```

```{r}
training <- ham_spam_df[pred,]
testing <- ham_spam_df[-pred,]
```

\
We will be using function RandomForest algorithm for classification and regression. \
We will use the randomForest classifier with 500 trees. \
The model shows 99.7% accuracy for the test data frame. \

```{r message = FALSE}
library(randomForest)
```

```{r}

classifier <-  randomForest(x = training, y = training$tag, ntree = 500) 
predicted <-  predict(classifier, newdata = testing)

confusionMatrix(table(predicted,testing$tag))

```
\

## Conclusion

In conclusion, The Random Forest was used as a classifier for the model,and it helped to achieve 99% accuracy. From what we gathered the predicted new document will be ham, not spam. 

\
